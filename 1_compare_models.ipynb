{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic dataset - Binary classification\n",
    "\n",
    "The Titanic dataset present a binary classification problem, where the goal is to predict whether a passenger survived or not.   \n",
    "In this notebook, I will build a simple Random Forest model to predict the survival of passengers.\n",
    "\n",
    "Will import the data cleaned in the previous step, with the following features:\n",
    "\n",
    "| Variable | Definition                          | Value                        |\n",
    "|----------|-------------------------------------|----------------------------|\n",
    "| survival | Survival                            | 0=No, 1=Yes            |\n",
    "| pclass   | Ticket class                        | 1=1st, 2=2nd, 3=3rd  |\n",
    "| sex      | Sex                                 | 0=Female, 1=Male                           |\n",
    "| Age      | Age in years                        |                            |\n",
    "| sibsp    | # of siblings / spouses aboard the Titanic |                    |\n",
    "| parch    | # of parents / children aboard the Titanic |                    |\n",
    "| fare     | Passenger fare                      |                            |\n",
    "| cabin    | Cabin number                        | 0=NaN/Unidentified, 1=Yes/Valid Cabin nr                           |\n",
    "| embarked | Port of Embarkation                 | 0=Cherbourg, 1=Queenstown, 2=Southampton |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape (rows, columns): (891, 18)\n",
      "Test dataset shape (rows, columns): (418, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>SibSp_5</th>\n",
       "      <th>SibSp_8</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Parch_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass_2  Pclass_3  Sex_1  SibSp_1  SibSp_2  \\\n",
       "0            1         0     False      True   True     True    False   \n",
       "1            2         1     False     False  False     True    False   \n",
       "2            3         1     False      True  False    False    False   \n",
       "\n",
       "   SibSp_3  SibSp_4  SibSp_5  SibSp_8  Parch_1  Parch_2  Parch_3  Parch_4  \\\n",
       "0    False    False    False    False    False    False    False    False   \n",
       "1    False    False    False    False    False    False    False    False   \n",
       "2    False    False    False    False    False    False    False    False   \n",
       "\n",
       "   Parch_5  Parch_6  Parch_9  \n",
       "0    False    False    False  \n",
       "1    False    False    False  \n",
       "2    False    False    False  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load cleaned data\n",
    "train_data = pd.read_csv('data/train_clean_subsetFeatures.csv')\n",
    "test_data = pd.read_csv('data/test_clean_subsetFeatures.csv')\n",
    "\n",
    "# print the shape of the data\n",
    "print('Train dataset shape (rows, columns):', train_data.shape)\n",
    "print('Test dataset shape (rows, columns):', test_data.shape)\n",
    "\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>SibSp_5</th>\n",
       "      <th>SibSp_8</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Parch_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass_2  Pclass_3  Sex_1  SibSp_1  SibSp_2  SibSp_3  SibSp_4  \\\n",
       "0          892     False      True   True    False    False    False    False   \n",
       "1          893     False      True  False     True    False    False    False   \n",
       "2          894      True     False   True    False    False    False    False   \n",
       "\n",
       "   SibSp_5  SibSp_8  Parch_1  Parch_2  Parch_3  Parch_4  Parch_5  Parch_6  \\\n",
       "0    False    False    False    False    False    False    False    False   \n",
       "1    False    False    False    False    False    False    False    False   \n",
       "2    False    False    False    False    False    False    False    False   \n",
       "\n",
       "   Parch_9  \n",
       "0    False  \n",
       "1    False  \n",
       "2    False  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models\n",
    "\n",
    "1) Logistic Regression\n",
    "2) Random Forest (subset of features)\n",
    "3) Random Forest (all features)\n",
    "4) Support Vector Machine (SVM)\n",
    "5) Xtreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>Cabin_1</th>\n",
       "      <th>Embarked_1</th>\n",
       "      <th>Embarked_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Fare  SibSp  Parch  Pclass_2  Pclass_3  Sex_1  Cabin_1  Embarked_1  \\\n",
       "0 -0.58 -0.50   0.48  -0.44     False      True   True    False       False   \n",
       "1  0.66  0.73   0.48  -0.44     False     False  False     True       False   \n",
       "2 -0.27 -0.49  -0.48  -0.44     False      True  False    False       False   \n",
       "\n",
       "   Embarked_2  \n",
       "0        True  \n",
       "1       False  \n",
       "2        True  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load cleaned data\n",
    "train_data = pd.read_csv('data/train_clean_allFeatures.csv')\n",
    "test_data = pd.read_csv('data/test_clean_allFeatures.csv')\n",
    "\n",
    "y = train_data[\"Survived\"] # target variable\n",
    "\n",
    "X = train_data.drop([\"Survived\", \"PassengerId\"], axis=1)\n",
    "X_test = test_data.drop([\"PassengerId\"], axis=1)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: [0.81564246 0.79213483 0.78651685 0.79213483 0.83707865] | Mean value: 0.805\n",
      "Cross-Validation F1:       [0.75912409 0.72180451 0.72058824 0.69918699 0.77165354] | Mean value: 0.734\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "lr = LogisticRegression(max_iter = 2000, random_state=1)\n",
    "cv_accuracy = cross_val_score(lr, X, y, cv=5, scoring='accuracy')\n",
    "cv_f1 = cross_val_score(lr, X, y, cv=5, scoring='f1')\n",
    "\n",
    "print(f'Cross-Validation Accuracy: {cv_accuracy} | Mean value: {round(cv_accuracy.mean(),3)}')\n",
    "print(f'Cross-Validation F1:       {cv_f1} | Mean value: {round(cv_f1.mean(),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: [0.73743017 0.80898876 0.80337079 0.76966292 0.81460674] | Mean value: 0.787\n",
      "Cross-Validation F1:       [0.52525253 0.73846154 0.72440945 0.66666667 0.74015748] | Mean value: 0.679\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model - subset of features\n",
    "train_data = pd.read_csv('data/train_clean_subsetFeatures.csv')\n",
    "test_data = pd.read_csv('data/test_clean_subsetFeatures.csv')\n",
    "\n",
    "y = train_data[\"Survived\"] # target variable\n",
    "X = train_data.drop([\"Survived\", \"PassengerId\"], axis=1)\n",
    "X_test = test_data.drop([\"PassengerId\"], axis=1)\n",
    "\n",
    "rf_subset = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "cv_accuracy = cross_val_score(rf_subset, X, y, cv=5, scoring='accuracy')\n",
    "cv_f1 = cross_val_score(rf_subset, X, y, cv=5, scoring='f1')\n",
    "\n",
    "print(f'Cross-Validation Accuracy: {cv_accuracy} | Mean value: {round(cv_accuracy.mean(),3)}')\n",
    "print(f'Cross-Validation F1:       {cv_f1} | Mean value: {round(cv_f1.mean(),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned data - back to using all features\n",
    "train_data = pd.read_csv('data/train_clean_allFeatures.csv')\n",
    "test_data = pd.read_csv('data/test_clean_allFeatures.csv')\n",
    "\n",
    "y = train_data[\"Survived\"] # target variable\n",
    "X = train_data.drop([\"Survived\", \"PassengerId\"], axis=1)\n",
    "X_test = test_data.drop([\"PassengerId\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: [0.80446927 0.78651685 0.87078652 0.79775281 0.84831461] | Mean value: 0.822\n",
      "Cross-Validation F1:       [0.73282443 0.71212121 0.82170543 0.69491525 0.80291971] | Mean value: 0.753\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model - all features\n",
    "rf = RandomForestClassifier(n_estimators=150, max_depth=10, random_state=1)\n",
    "cv_accuracy = cross_val_score(rf, X, y, cv=5, scoring='accuracy')\n",
    "cv_f1 = cross_val_score(rf, X, y, cv=5, scoring='f1')\n",
    "\n",
    "print(f'Cross-Validation Accuracy: {cv_accuracy} | Mean value: {round(cv_accuracy.mean(),3)}')\n",
    "print(f'Cross-Validation F1:       {cv_f1} | Mean value: {round(cv_f1.mean(),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: [0.82681564 0.82022472 0.79775281 0.81460674 0.85955056] | Mean value: 0.824\n",
      "Cross-Validation F1:       [0.76691729 0.75384615 0.72307692 0.72268908 0.80916031] | Mean value: 0.755\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier (SVC) model\n",
    "svc = SVC(probability = True)\n",
    "cv_accuracy = cross_val_score(svc, X, y, cv=5, scoring='accuracy')\n",
    "cv_f1 = cross_val_score(svc, X, y, cv=5, scoring='f1')\n",
    "\n",
    "print(f'Cross-Validation Accuracy: {cv_accuracy} | Mean value: {round(cv_accuracy.mean(),3)}')\n",
    "print(f'Cross-Validation F1:       {cv_f1} | Mean value: {round(cv_f1.mean(),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: [0.79329609 0.82022472 0.84831461 0.78089888 0.85955056] | Mean value: 0.82\n",
      "Cross-Validation F1:       [0.72592593 0.75757576 0.8        0.69291339 0.81751825] | Mean value: 0.759\n"
     ]
    }
   ],
   "source": [
    "# Xtreme Gradient Boosting (XGBoost) model\n",
    "xgb = XGBClassifier(random_state =1)\n",
    "cv_accuracy = cross_val_score(xgb, X, y, cv=5, scoring='accuracy')\n",
    "cv_f1 = cross_val_score(xgb, X, y, cv=5, scoring='f1')\n",
    "\n",
    "print(f'Cross-Validation Accuracy: {cv_accuracy} | Mean value: {round(cv_accuracy.mean(),3)}')\n",
    "print(f'Cross-Validation F1:       {cv_f1} | Mean value: {round(cv_f1.mean(),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: [0.81005587 0.79775281 0.85393258 0.79213483 0.85955056] | Mean value: 0.823\n",
      "Cross-Validation F1:       [0.734375   0.72727273 0.79365079 0.69918699 0.81751825] | Mean value: 0.754\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier(random_state =1)\n",
    "cv_accuracy = cross_val_score(gbc, X, y, cv=5, scoring='accuracy')\n",
    "cv_f1 = cross_val_score(gbc, X, y, cv=5, scoring='f1')\n",
    "\n",
    "print(f'Cross-Validation Accuracy: {cv_accuracy} | Mean value: {round(cv_accuracy.mean(),3)}')\n",
    "print(f'Cross-Validation F1:       {cv_f1} | Mean value: {round(cv_f1.mean(),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model Performance\n",
    "\n",
    "| Model       | Accuracy | F1-score    |\n",
    "|-------------|----------|-------------|\n",
    "| Logistic Regression  | 80.5     | 73.4        |\n",
    "| Random Forest subset | 78.7     | 67.9        |\n",
    "| Random Forest all    | 82.2     | 75.3        |\n",
    "| SVM                  | 62.4     | 75.5        |\n",
    "| XGBoost              | 82.0     | 75.9        |\n",
    "| Gradient Boosting    | 82.3     | 75.4        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "Use GridSearchCV to find the best parameters for the models, while RandomizedSearchCV for Random Forest and XG Boost mopdels to reduce the computational time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report stats for each model\n",
    "def clf_performance(classifier, model_name):\n",
    "    print(model_name)\n",
    "    print('Best Score: ' + str(classifier.best_score_))\n",
    "    print('Best Parameters: ' + str(classifier.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Best Score: 0.8125842696629213\n",
      "Best Parameters: {'C': 0.14384498882876628, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model - hyperparameter tuning\n",
    "lr = LogisticRegression(random_state = 1)\n",
    "param_grid = {'max_iter': [2000],\n",
    "                'C': np.logspace(-4, 2, 20),\n",
    "                'penalty': ['l2'],\n",
    "                'solver': ['liblinear']}\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf_lr = GridSearchCV(lr, param_grid=param_grid, cv=10, verbose=True, n_jobs=-1) # n_jobs=-1 means all processors\n",
    "best_clf_lr = clf_lr.fit(X, y)\n",
    "clf_performance(best_clf_lr,'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Score: 0.79686774213797\n",
    "Best Parameters: {'C': 29.763514416313132, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "\n",
    "Best Score: 0.79686774213797\n",
    "Best Parameters: {'C': 23.357214690901213, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "\n",
    "Best Score: 0.7957441466323519\n",
    "Best Parameters: {'C': 11.288378916846883, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "\n",
    "Best Score: 0.7957303370786517\n",
    "Best Parameters: {'C': 2.6366508987303554, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest model - hyperparameter tuning (subset of features)\n",
    "train_data = pd.read_csv('data/train_clean_subsetFeatures.csv')\n",
    "test_data = pd.read_csv('data/test_clean_subsetFeatures.csv')\n",
    "\n",
    "y = train_data[\"Survived\"] # target variable\n",
    "X = train_data.drop([\"Survived\", \"PassengerId\"], axis=1)\n",
    "X_test = test_data.drop([\"PassengerId\"], axis=1)\n",
    "\n",
    "# Because of the large potential search space, we 1) use RandomizedSearchCV to narrow down the search space\n",
    "# and 2) use GridSearchCV on the smaller search space to find the best parameters\n",
    "\n",
    "# # 1) RandomizedSearchCV - to narrow down search space\n",
    "# rf_subset = RandomForestClassifier(random_state = 1)\n",
    "# param_grid =  {'n_estimators': [100,500,1000], \n",
    "#                 'bootstrap': [True,False],\n",
    "#                 'max_depth': [3,5,10,20,50,75],\n",
    "#                 'max_features': ['auto','sqrt'],\n",
    "#                 'min_samples_leaf': [1,2,4,10],\n",
    "#                 'min_samples_split': [2,5,10]}\n",
    "\n",
    "# clf_rf_subset_rnd = RandomizedSearchCV(rf_subset, param_distributions=param_grid, n_iter=100, cv=5, verbose=True, n_jobs=-1)\n",
    "# best_rf_subset_rnd = clf_rf_subset_rnd.fit(X, y)\n",
    "# clf_performance(best_rf_subset_rnd,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "Random Forest\n",
      "Best Score: 0.8002247191011236\n",
      "Best Parameters: {'bootstrap': True, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model (subset of features)\n",
    "# 2) GridSearchCV on smaller search space\n",
    "param_grid =  {'n_estimators': [400, 500],\n",
    "                'bootstrap': [True],\n",
    "                'max_depth': [3,4,5],\n",
    "                'max_features': ['sqrt'],\n",
    "                'min_samples_leaf': [2,3,4],\n",
    "                'min_samples_split': [2,3]}\n",
    "clf_rf = GridSearchCV(rf, param_grid=param_grid, cv=10, verbose=True, n_jobs=-1)\n",
    "best_clf_rf = clf_rf.fit(X, y)\n",
    "clf_performance(best_clf_rf,'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Score: 0.7879354717218002\n",
    "Best Parameters: {'bootstrap': True, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 300}\n",
    "\n",
    "Best Score: 0.8013483146067415\n",
    "Best Parameters: {'bootstrap': True, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}\n",
    "\n",
    "Best Score: 0.8002247191011236\n",
    "Best Parameters: {'bootstrap': True, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest model - hyperparameter tuning (all features)\n",
    "# load cleaned data - back to using all features\n",
    "train_data = pd.read_csv('data/train_clean_allFeatures.csv')\n",
    "test_data = pd.read_csv('data/test_clean_allFeatures.csv')\n",
    "\n",
    "y = train_data[\"Survived\"] # target variable\n",
    "X = train_data.drop([\"Survived\", \"PassengerId\"], axis=1)\n",
    "X_test = test_data.drop([\"PassengerId\"], axis=1)\n",
    "\n",
    "# Because of the large potential search space, we 1) use RandomizedSearchCV to narrow down the search space\n",
    "# and 2) use GridSearchCV on the smaller search space to find the best parameters\n",
    "\n",
    "# # 1) RandomizedSearchCV - to narrow down search space\n",
    "# rf = RandomForestClassifier(random_state = 1)\n",
    "# param_grid =  {'n_estimators': [300, 400, 425],\n",
    "#                 'bootstrap': [True],\n",
    "#                 'max_depth': [4,5,6],\n",
    "#                 'max_features': ['sqrt'],\n",
    "#                 'min_samples_leaf': [2,3],\n",
    "#                 'min_samples_split': [2,3,4]}\n",
    "\n",
    "# clf_rf_rnd = RandomizedSearchCV(rf, param_distributions=param_grid, n_iter=100, cv=5, verbose=True, n_jobs=-1)\n",
    "# best_rf_rnd = clf_rf_rnd.fit(X, y)\n",
    "# clf_performance(best_rf_rnd,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "Random Forest\n",
      "Best Score: 0.8260549313358302\n",
      "Best Parameters: {'bootstrap': True, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model (all features)\n",
    "# 2) GridSearchCV on smaller search space\n",
    "param_grid =  {'n_estimators': [400, 500],\n",
    "                'bootstrap': [True],\n",
    "                'max_depth': [4,5,6],\n",
    "                'max_features': ['sqrt'],\n",
    "                'min_samples_leaf': [2,3,4],\n",
    "                'min_samples_split': [2,3]}\n",
    "clf_rf = GridSearchCV(rf, param_grid=param_grid, cv=10, verbose=True, n_jobs=-1)\n",
    "best_clf_rf = clf_rf.fit(X, y)\n",
    "clf_performance(best_clf_rf,'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Score: 0.831648986253217\n",
    "Best Parameters: {'bootstrap': True, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 400}\n",
    "\n",
    "Best Score: 0.8249387985688281\n",
    "Best Parameters: {'bootstrap': True, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 400}\n",
    "\n",
    "Best Score: 0.8260549313358302\n",
    "Best Parameters: {'bootstrap': True, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "SVC\n",
      "Best Score: 0.8215730337078652\n",
      "Best Parameters: {'C': 1.0, 'degree': 2, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier (SVC) model - hyperparameter tuning\n",
    "svc = SVC(probability = True)\n",
    "param_grid = tuned_parameters = [\n",
    "    {'kernel': ['rbf'], 'degree':[2], 'C': [0.5, 0.7, 1.0]},\n",
    "    #  {'kernel': ['linear'], 'C': [1]}\n",
    "    # {'kernel': ['poly'], 'degree':[2], 'C': [1e03]}\n",
    "]\n",
    "clf_svc = GridSearchCV(svc, param_grid=param_grid, cv=10, verbose=True, n_jobs=-1)\n",
    "best_clf_svc = clf_svc.fit(X, y)\n",
    "clf_performance(best_clf_svc,'SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Score: 0.823 | \n",
    "Best Parameters: {'C': 1.5, 'degree': 2, 'kernel': 'rbf'}\n",
    "\n",
    "Best Score: 0.822 | \n",
    "Best Parameters: {'C': 1.0, 'degree': 2, 'kernel': 'rbf'}\n",
    "\n",
    "Best Score: 0.798 | \n",
    "Best Parameters: {'C': 0.5, 'degree': 2, 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 18\u001b[0m\n\u001b[0;32m      5\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m150\u001b[39m],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.5\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# 'sampling_method': ['uniform']\u001b[39;00m\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     17\u001b[0m clf_xgb_rnd \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(xgb, param_distributions \u001b[38;5;241m=\u001b[39m param_grid, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m best_clf_xgb_rnd \u001b[38;5;241m=\u001b[39m \u001b[43mclf_xgb_rnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m clf_performance(best_clf_xgb_rnd,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# XGBoost model - hyperparameter tuning\n",
    "\n",
    "# 1) RandomizedSearchCV - to narrow down search space\n",
    "xgb = XGBClassifier(random_state = 1)\n",
    "param_grid = {\n",
    "    'n_estimators': [150],\n",
    "    'colsample_bytree': [0.3, 0.5],\n",
    "    'max_depth': [9, 10, 11],\n",
    "    'reg_alpha': [0.5, 0.9],\n",
    "    'reg_lambda': [3, 4, 5],\n",
    "    'subsample': [0.3, 0.4],\n",
    "    'learning_rate':[0,2, 0.25],\n",
    "    'gamma': [0.6, 0.8, 1],\n",
    "    'min_child_weight':[2, 3],\n",
    "    # 'sampling_method': ['uniform']\n",
    "}\n",
    "clf_xgb_rnd = RandomizedSearchCV(xgb, param_distributions = param_grid, n_iter = 1000, cv = 10, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb_rnd = clf_xgb_rnd.fit(X,y)\n",
    "clf_performance(best_clf_xgb_rnd,'XGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Score: 0.8406556780996244\n",
    "Best Parameters: {'colsample_bytree': 0.6, 'gamma': 0.5, 'learning_rate': 0.3, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 22, 'reg_alpha': 0, 'reg_lambda': 2.0, 'subsample': 0.8}\n",
    "\n",
    "Best Score: 0.8406741573033708\n",
    "Best Parameters: {'subsample': 0.9, 'reg_lambda': 1.8, 'reg_alpha': 0.1, 'n_estimators': 25, 'min_child_weight': 2, 'max_depth': 12, 'learning_rate': 0.3, 'gamma': 0.6, 'colsample_bytree': 0.7}\n",
    "\n",
    "Best Score: 0.8451560549313358\n",
    "Best Parameters: {'subsample': 0.5, 'reg_lambda': 2, 'reg_alpha': 0.001, 'n_estimators': 50, 'min_child_weight': 4, 'max_depth': 10, 'learning_rate': 0.3, 'gamma': 1, 'colsample_bytree': 0.6}\n",
    "\n",
    "Best Score: 0.8418102372034955\n",
    "Best Parameters: {'subsample': 0.5, 'reg_lambda': 2.2, 'reg_alpha': 0.01, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.3, 'gamma': 0.6, 'colsample_bytree': 0.6}\n",
    "\n",
    "Best Score: 0.8451810237203496\n",
    "Best Parameters: {'subsample': 0.4, 'reg_lambda': 3, 'reg_alpha': 0.1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.3, 'gamma': 0.8, 'colsample_bytree': 0.6}\n",
    "\n",
    "Best Score: 0.8350686641697879\n",
    "Best Parameters: {'subsample': 0.3, 'reg_lambda': 3, 'reg_alpha': 0.5, 'n_estimators': 150, 'min_child_weight': 2, 'max_depth': 11, 'learning_rate': 0.25, 'gamma': 0.6, 'colsample_bytree': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 864 candidates, totalling 8640 fits\n",
      "XGB\n",
      "Best Score: 0.8350686641697879\n",
      "Best Parameters: {'colsample_bytree': 0.5, 'gamma': 0.6, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 2, 'n_estimators': 150, 'reg_alpha': 0.5, 'reg_lambda': 3, 'subsample': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost model - hyperparameter tuning\n",
    "\n",
    "# 2) GridSearchCV on smaller search space\n",
    "xgb = XGBClassifier(random_state = 1)\n",
    "param_grid = {\n",
    "    'n_estimators': [150],\n",
    "    'colsample_bytree': [0.3, 0.5],\n",
    "    'max_depth': [9, 10, 11],\n",
    "    'reg_alpha': [0.5, 0.6],\n",
    "    'reg_lambda': [3, 4],\n",
    "    'subsample': [0.3, 0.4],\n",
    "    'learning_rate':[0,2, 0.25],\n",
    "    'gamma': [0.6, 0.8, 1],\n",
    "    'min_child_weight':[2, 3],\n",
    "    # 'sampling_method': ['uniform']\n",
    "}\n",
    "clf_xgb = GridSearchCV(xgb, param_grid=param_grid, cv=10, verbose=True, n_jobs=-1)\n",
    "best_clf_xgb = clf_xgb.fit(X,y)\n",
    "clf_performance(best_clf_xgb,'XGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Score: 0.8406556780996244\n",
    "Best Parameters: {'colsample_bytree': 0.6, 'gamma': 0.5, 'learning_rate': 0.3, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 22, 'reg_alpha': 0, 'reg_lambda': 2.0, 'sampling_method': 'uniform', 'subsample': 0.8}\n",
    "\n",
    "Best Score: 0.8350686641697879\n",
    "Best Parameters: {'colsample_bytree': 0.5, 'gamma': 0.6, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 2, 'n_estimators': 150, 'reg_alpha': 0.5, 'reg_lambda': 3, 'subsample': 0.3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "Gradient Boosting Classifier\n",
      "Best Score: 0.838414481897628\n",
      "Best Parameters: {'learning_rate': 0.08, 'loss': 'exponential', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier - hyperparameter tuning\n",
    "gbc = GradientBoostingClassifier(random_state = 1)\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'max_depth': [3, 4, 5],\n",
    "#     'min_samples_split': [2, 3],\n",
    "#     'min_samples_leaf': [1, 2]\n",
    "# }\n",
    "param_grid = {\n",
    "    'n_estimators': [200],            # Increase number of trees\n",
    "    'learning_rate': [0.08],     # Decrease learning rate\n",
    "    'max_depth': [4, 5, 6],           # Reduce tree depth\n",
    "    'min_samples_split': [4, 5],   # Increase min_samples_split\n",
    "    'min_samples_leaf': [1, 2],    # Increase min_samples_leaf\n",
    "    'subsample': [0.4, 0.5],     # Include more aggressive subsampling\n",
    "    'max_features': ['sqrt'],         # Limit max_features for each split\n",
    "    'loss': ['exponential']           # Consider different loss functions\n",
    "}\n",
    "clf_gbc = GridSearchCV(gbc, param_grid=param_grid, cv=10, verbose=True, n_jobs=-1)\n",
    "best_clf_gbc = clf_gbc.fit(X, y)\n",
    "clf_performance(best_clf_gbc,'Gradient Boosting Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Score: 0.8440199750312111\n",
    "Best Parameters: {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "\n",
    "Best Score: 0.8339150084740444\n",
    "Best Parameters: {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50, 'subsample': 0.7}\n",
    "\n",
    "Best Score: 0.838390559286925\n",
    "Best Parameters: {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "Best Score: 0.8350561797752809\n",
    "Best Parameters: {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 150, 'subsample': 0.6}\n",
    "\n",
    "Best Score: 0.838414481897628\n",
    "Best Parameters: {'learning_rate': 0.08, 'loss': 'exponential', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Tuned Model Performance\n",
    "\n",
    "| Model                | Accuracy | Accuracy_tuned |  Accuracy Kaggle test_set | \n",
    "|----------------------|----------|----------------|-----------|\n",
    "| Logistic Regression  | 80.5     | 79.6           |     |\n",
    "| Random Forest subset | 78.7      | 80.0          |     |\n",
    "| Random Forest all    | 82.2     | 82.6           |     |\n",
    "| SVM                  | 82.4     | 82.2           |     |\n",
    "| XGBoost              | 82.0      | 83.5          |     |\n",
    "| Gradient Boosting    | 82.3     | 83.8           |     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Age\n- Cabin_1\n- Embarked_1\n- Embarked_2\n- Fare\n- ...\nFeature names seen at fit time, yet now missing:\n- Parch_1\n- Parch_2\n- Parch_3\n- Parch_4\n- Parch_5\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save predictions from the models\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Logistic Regression\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m predictions_lr \u001b[38;5;241m=\u001b[39m \u001b[43mbest_clf_lr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m'\u001b[39m: test_data\u001b[38;5;241m.\u001b[39mPassengerId, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions_lr})\n\u001b[0;32m      5\u001b[0m output\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmissions/logistic_regression.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:546\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \n\u001b[0;32m    530\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    545\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 351\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    353\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:332\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    329\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    330\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 332\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\kaggle_ML_env\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Age\n- Cabin_1\n- Embarked_1\n- Embarked_2\n- Fare\n- ...\nFeature names seen at fit time, yet now missing:\n- Parch_1\n- Parch_2\n- Parch_3\n- Parch_4\n- Parch_5\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Save predictions from the models\n",
    "# Logistic Regression\n",
    "predictions_lr = best_clf_lr.predict(X_test)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions_lr})\n",
    "output.to_csv('submissions/logistic_regression.csv', index=False)\n",
    "\n",
    "# Random Forest\n",
    "predictions_rf = best_clf_rf.predict(X_test)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions_rf})\n",
    "output.to_csv('submissions/random_forest_3.csv', index=False)\n",
    "\n",
    "# SVC\n",
    "predictions_svc = best_clf_svc.predict(X_test)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions_svc})\n",
    "output.to_csv('submissions/svc.csv', index=False)\n",
    "\n",
    "# XGBoost\n",
    "predictions_xgb = best_clf_xgb.predict(X_test)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions_xgb})\n",
    "output.to_csv('submissions/xgboost.csv', index=False)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "predictions_gbc = best_clf_gbc.predict(X_test)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions_gbc})\n",
    "output.to_csv('submissions/gradient_boosting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_ML_env",
   "language": "python",
   "name": "kaggle_ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
